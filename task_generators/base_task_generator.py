"""
Base task generator class for Minecraft data collection.

Each task generator corresponds to one task type (chase, orbit, etc.)
and is responsible for:
1. Sampling randomized task configurations
2. Generating docker-compose files with unique ports/displays per worker
3. Running episodes and collecting output
"""

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, Any, Optional
import random
import subprocess
import yaml
import json
import copy
from datetime import datetime
import tempfile

from .base_compose_template import get_base_compose_template


class BaseTaskGenerator(ABC):
    """
    Base class for task generators.
    Each subclass corresponds to one task type (e.g., chase, orbit).
    """
    
    def __init__(
        self,
        task_name: str,
        output_root: Path,
        data_root: Path,
        camera_root: Path,
        base_port: int = 25565,
        base_rcon_port: int = 25575,
        base_vnc_display: int = 99,
        base_vnc_port: int = 5901,
        base_novnc_port: int = 6901,
        worker_id: int = 0,
        seed: Optional[int] = None
    ):
        """
        Initialize task generator.
        
        Args:
            task_name: Name of the task type (e.g., "chase", "orbit")
            output_root: Root directory for output files
            data_root: Root directory for MC server data
            camera_root: Root directory for camera data/output
            base_port: Base Minecraft server port
            base_rcon_port: Base RCON port
            base_vnc_display: Base X display number for VNC
            base_vnc_port: Base VNC port
            base_novnc_port: Base noVNC port
            worker_id: Unique worker ID (for port/display assignment)
            seed: Random seed for reproducibility
        """
        self.task_name = task_name
        self.output_root = Path(output_root).absolute()
        self.data_root = Path(data_root).absolute()
        self.camera_root = Path(camera_root).absolute()
        
        self.base_port = base_port
        self.base_rcon_port = base_rcon_port
        self.base_vnc_display = base_vnc_display
        self.base_vnc_port = base_vnc_port
        self.base_novnc_port = base_novnc_port
        self.worker_id = worker_id
        
        # Create worker-specific RNG for reproducibility
        self.rng = random.Random(seed if seed is not None else random.randint(0, 2**32-1))
        
        # Counter for episodes generated by this worker
        self.episode_counter = 0
        
        # Create output directories
        self.output_root.mkdir(parents=True, exist_ok=True)
        self.data_root.mkdir(parents=True, exist_ok=True)
        self.camera_root.mkdir(parents=True, exist_ok=True)
    

    def get_global_env_vars(self) -> Dict[str, str]:
        """Return global environment variables as a dictionary"""
        return {
            "MC_HOST": "127.0.0.1",
            "RCON_HOST": "127.0.0.1", 
            "RCON_PASSWORD": "research",
            "RECEIVER_HOST": "127.0.0.1",
            "RECEIVER_PORT": "8091",
            "BOT_NAME": "Alpha",
            "OTHER_BOT_NAME": "Bravo",
            "COLOR": "red",
            "COORD_PORT": "8093",
            "OTHER_COORD_HOST": "127.0.0.1",
            "OTHER_COORD_PORT": "8094",
            "EPISODES_NUM": "1",
            "EPISODE_START_ID": "0",
            "ITERATIONS_NUM_PER_EPISODE": "5",
            "BOOTSTRAP_WAIT_TIME": "20",
            "CAMERA_READY_RETRIES": "30",
            "CAMERA_READY_CHECK_INTERVAL": "2000",
            "TELEPORT_CENTER_X": "0",
            "TELEPORT_CENTER_Z": "0",
            "TELEPORT_RADIUS": "500",
            "WALK_TIMEOUT": "5",
            "MC_VERSION": "1.20.4"
        }
    
    @abstractmethod
    def get_task_env_vars(self) -> Dict[str, str]:
        """
        Return task-specific environment variables as a dictionary.
        Each task type implements its own randomization strategy.
        
        Returns:
            Dictionary of environment variable name -> value (as string)
            
        Example:
            return {
                "CHASE_DURATION_MS": "10000",
                "CHASE_MIN_DISTANCE": "3.0"
            }
        """
        pass
    
    def run_task_episode(self, save_config: bool = True) -> Dict[str, Any]:
        """
        Generate and run a single episode for this task.
        This is the main entry point similar to run_stack.sh.
        
        Args:
            save_config: Whether to save config JSON for reproducibility
            
        Returns:
            Dictionary with episode metadata and results
        """
        # 1. Setup unique infrastructure settings based on worker_id
        port_offset = self.worker_id * 100
        mc_port = self.base_port + port_offset
        rcon_port = self.base_rcon_port + port_offset
        vnc_display_alpha = self.base_vnc_display + (self.worker_id * 2)
        vnc_display_bravo = self.base_vnc_display + (self.worker_id * 2) + 1
        vnc_port_alpha = self.base_vnc_port + (self.worker_id * 2)
        vnc_port_bravo = self.base_vnc_port + (self.worker_id * 2) + 1
        novnc_port_alpha = self.base_novnc_port + (self.worker_id * 2)
        novnc_port_bravo = self.base_novnc_port + (self.worker_id * 2) + 1
        instance_id = self.worker_id * 10000 + self.episode_counter
        
        # 2. Setup worker-specific directories
        episode_id = f"worker{self.worker_id:03d}_ep{self.episode_counter:06d}"
        
        worker_data_dir = self.data_root / f"worker_{self.worker_id}"
        episode_data_dir = worker_data_dir / f"episode_{self.episode_counter}"
        data_dir = str(episode_data_dir)
        output_dir = str(self.output_root)
        
        worker_camera_dir = self.camera_root / f"worker_{self.worker_id}" / f"ep_{self.episode_counter}"
        camera_data_dir_alpha = str(worker_camera_dir / "data_alpha")
        camera_data_dir_bravo = str(worker_camera_dir / "data_bravo")
        camera_output_dir_alpha = str(worker_camera_dir / "output_alpha")
        camera_output_dir_bravo = str(worker_camera_dir / "output_bravo")
        
        # Create all directories
        for dir_path in [data_dir, camera_data_dir_alpha, camera_data_dir_bravo, 
                         camera_output_dir_alpha, camera_output_dir_bravo]:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
        
        # 3. Generate docker-compose file
        compose_file = self._generate_compose_file(episode_id, mc_port, rcon_port, 
                                                 vnc_display_alpha, vnc_display_bravo,
                                                 vnc_port_alpha, vnc_port_bravo,
                                                 novnc_port_alpha, novnc_port_bravo,
                                                 instance_id, data_dir, output_dir,
                                                 camera_data_dir_alpha, camera_data_dir_bravo,
                                                 camera_output_dir_alpha, camera_output_dir_bravo)
        
        # 4. Save config for reproducibility (if needed)
        if save_config:
            config_data = {
                "bot_rng_seed": self.rng.randint(0, 2**31 - 1),
                "world_seed": self.rng.randint(0, 2**31 - 1),
                "task_env_vars": self.get_task_env_vars(),
                "global_env_vars": self.get_global_env_vars()
            }
            config_file = self.output_root / f"{episode_id}_{self.task_name}_config.json"
            with open(config_file, 'w') as f:
                json.dump(config_data, f, indent=2)
        
        # 5. Run the stack (similar to run_stack.sh)
        print(f"[Worker {self.worker_id}] Task: {self.task_name}, Episode: {self.episode_counter}")
        print(f"  MC Port: {mc_port}, RCON Port: {rcon_port}")
        print(f"  VNC Displays: :{vnc_display_alpha}, :{vnc_display_bravo}")
        
        start_time = datetime.now()
        try:
            self._run_docker_stack(compose_file, episode_id)
            success = True
            error = None
        except Exception as e:
            success = False
            error = str(e)
            print(f"[Worker {self.worker_id}] Episode {self.episode_counter} failed: {e}")
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # 6. Collect output information
        result = {
            "worker_id": self.worker_id,
            "task_name": self.task_name,
            "episode_number": self.episode_counter,
            "episode_id": episode_id,
            "success": success,
            "error": error,
            "duration_seconds": duration,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
        }
        
        self.episode_counter += 1
        return result
    
    def _generate_compose_file(self, episode_id: str, mc_port: int, rcon_port: int,
                             vnc_display_alpha: int, vnc_display_bravo: int,
                             vnc_port_alpha: int, vnc_port_bravo: int,
                             novnc_port_alpha: int, novnc_port_bravo: int,
                             instance_id: int, data_dir: str, output_dir: str,
                             camera_data_dir_alpha: str, camera_data_dir_bravo: str,
                             camera_output_dir_alpha: str, camera_output_dir_bravo: str) -> Path:
        """
        Generate docker-compose file by overriding base template.
        
        Args:
            episode_id: Unique episode identifier
            mc_port, rcon_port: Server ports
            vnc_display_alpha, vnc_display_bravo: VNC display numbers
            vnc_port_alpha, vnc_port_bravo: VNC ports
            novnc_port_alpha, novnc_port_bravo: noVNC ports
            instance_id: Unique instance ID
            data_dir, output_dir: Directory paths
            camera_data_dir_alpha, camera_data_dir_bravo: Camera data directories
            camera_output_dir_alpha, camera_output_dir_bravo: Camera output directories
            
        Returns:
            Path to generated docker-compose file
        """
        compose = copy.deepcopy(get_base_compose_template())
        
        # Get default terrain (flat grass for now, can be overridden by subclasses)
        terrain_json = json.dumps({
            "layers": [
                {"block": "minecraft:bedrock", "height": 1},
                {"block": "minecraft:stone", "height": 124},
                {"block": "minecraft:dirt", "height": 2},
                {"block": "minecraft:grass_block", "height": 1}
            ],
            "biome": "minecraft:plains"
        })
        
        # Get environment variable dictionaries
        global_env_vars = self.get_global_env_vars()
        task_env_vars = self.get_task_env_vars()
        
        # Override MC server settings
        mc_service = compose["services"]["mc"]
        mc_service["environment"]["SERVER_PORT"] = mc_port
        mc_service["environment"]["RCON_PORT"] = rcon_port
        mc_service["environment"]["SEED"] = str(self.rng.randint(0, 2**31 - 1))
        mc_service["environment"]["GENERATOR_SETTINGS"] = terrain_json
        mc_service["volumes"] = [f"{data_dir}:/data"]
        mc_service["healthcheck"]["test"] = [
            "CMD-SHELL",
            f"mc-monitor status --host localhost --port {mc_port}"
        ]
        
        # Override sender settings (CRITICAL: Set EPISODE_CATEGORY)
        for bot_name in ["sender_alpha", "sender_bravo"]:
            bot_service = compose["services"][bot_name]
            
            # Set global environment variables
            bot_service["environment"].update(global_env_vars)
            
            # Set task-specific environment variables (same for both bots)
            bot_service["environment"].update(task_env_vars)
            
            # Set bot-specific variables
            if bot_name == "sender_alpha":
                bot_service["environment"]["BOT_NAME"] = "Alpha"
                bot_service["environment"]["OTHER_BOT_NAME"] = "Bravo"
                bot_service["environment"]["COLOR"] = "red"
            else:  # sender_bravo
                bot_service["environment"]["BOT_NAME"] = "Bravo"
                bot_service["environment"]["OTHER_BOT_NAME"] = "Alpha"
                bot_service["environment"]["COLOR"] = "blue"
            
            # Set infrastructure variables
            bot_service["environment"]["MC_PORT"] = str(mc_port)
            bot_service["environment"]["RCON_PORT"] = str(rcon_port)
            bot_service["environment"]["BOT_RNG_SEED"] = str(self.rng.randint(0, 2**31 - 1))
            
            bot_service["volumes"] = [f"{output_dir}:/output"]
        
        # Override receiver settings
        for bot_name in ["receiver_alpha", "receiver_bravo"]:
            receiver_service = compose["services"][bot_name]
            receiver_service["environment"]["INSTANCE_ID"] = instance_id
            receiver_service["volumes"] = [f"{output_dir}:/output"]
        
        # Get absolute paths for camera scripts
        camera_scripts_dir = Path("/home/oscar/mc-multiplayer-data/camera").absolute()
        
        # Override camera_alpha settings
        camera_alpha = compose["services"]["camera_alpha"]
        camera_alpha["container_name"] = f"mc_camera_alpha_{episode_id}"
        camera_alpha["environment"]["MC_PORT"] = str(mc_port)
        camera_alpha["environment"]["DISPLAY"] = f":{vnc_display_alpha}"
        camera_alpha["environment"]["VNC_PORT"] = str(vnc_port_alpha)
        camera_alpha["environment"]["NOVNC_PORT"] = str(novnc_port_alpha)
        camera_alpha["volumes"] = [
            f"{camera_data_dir_alpha}:/root",
            f"{camera_output_dir_alpha}:/output",
            f"{camera_scripts_dir}/entrypoint.sh:/app/entrypoint.sh:ro",
            f"{camera_scripts_dir}/launch_minecraft.py:/app/launch_minecraft.py:ro"
        ]
        
        # Override camera_bravo settings
        camera_bravo = compose["services"]["camera_bravo"]
        camera_bravo["container_name"] = f"mc_camera_bravo_{episode_id}"
        camera_bravo["environment"]["MC_PORT"] = str(mc_port)
        camera_bravo["environment"]["DISPLAY"] = f":{vnc_display_bravo}"
        camera_bravo["environment"]["VNC_PORT"] = str(vnc_port_bravo)
        camera_bravo["environment"]["NOVNC_PORT"] = str(novnc_port_bravo)
        camera_bravo["volumes"] = [
            f"{camera_data_dir_bravo}:/root",
            f"{camera_output_dir_bravo}:/output",
            f"{camera_scripts_dir}/entrypoint.sh:/app/entrypoint.sh:ro",
            f"{camera_scripts_dir}/launch_minecraft.py:/app/launch_minecraft.py:ro"
        ]
        
        # Override camera follow helpers
        camera_alpha_follow = compose["services"]["camera_alpha_follow"]
        camera_alpha_follow["container_name"] = f"mc_camera_alpha_follow_{episode_id}"
        camera_alpha_follow["environment"]["RCON_PORT"] = str(rcon_port)
        camera_alpha_follow["volumes"] = [
            f"{camera_scripts_dir}/spectator.js:/app/spectator.js:ro",
            f"{camera_scripts_dir}/package.json:/app/package.json:ro"
        ]
        
        camera_bravo_follow = compose["services"]["camera_bravo_follow"]
        camera_bravo_follow["container_name"] = f"mc_camera_bravo_follow_{episode_id}"
        camera_bravo_follow["environment"]["RCON_PORT"] = str(rcon_port)
        camera_bravo_follow["volumes"] = [
            f"{camera_scripts_dir}/spectator.js:/app/spectator.js:ro",
            f"{camera_scripts_dir}/package.json:/app/package.json:ro"
        ]
        
        # Write to temp file
        temp_dir = Path(tempfile.gettempdir()) / f"mc_worker_{self.worker_id}"
        temp_dir.mkdir(exist_ok=True)
        compose_file = temp_dir / f"docker-compose-{episode_id}.yml"
        
        with open(compose_file, 'w') as f:
            yaml.dump(compose, f, default_flow_style=False, sort_keys=False)
        
        return compose_file
    
    def _run_docker_stack(self, compose_file: Path, episode_id: str):
        """
        Run docker compose stack (mimics run_stack.sh).
        
        Args:
            compose_file: Path to docker-compose file
            episode_id: Unique episode identifier
            config: TaskConfig for this episode
        """
        project_name = f"mc_{episode_id}"
        log_dir = self.output_root / "logs" / episode_id
        log_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # Pull images
            print(f"[Worker {self.worker_id}] Pulling images...")
            result = subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file), "pull"],
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            if result.returncode != 0:
                print(f"[Worker {self.worker_id}] Pull failed:")
                print(result.stderr)
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            
            # Start stack
            print(f"[Worker {self.worker_id}] Starting stack...")
            result = subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file), "up", "-d"],
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            if result.returncode != 0:
                print(f"[Worker {self.worker_id}] Start failed:")
                print(result.stderr)
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            
            # Start capturing logs for all services
            log_services = ["mc", "sender_alpha", "sender_bravo", "receiver_alpha", "receiver_bravo",
                          "camera_alpha", "camera_bravo", "camera_alpha_follow", "camera_bravo_follow"]
            log_processes = []
            
            for service in log_services:
                log_file = log_dir / f"{service}.log"
                print(f"[Worker {self.worker_id}] Capturing logs for {service} -> {log_file}")
                with open(log_file, 'w') as f:
                    proc = subprocess.Popen(
                        ["docker", "compose", "-p", project_name, "-f", str(compose_file), 
                         "logs", "--no-color", "--timestamps", "--follow", service],
                        stdout=f,
                        stderr=subprocess.STDOUT,
                        cwd="/home/oscar/mc-multiplayer-data"
                    )
                    log_processes.append(proc)
            
            # Wait for senders to complete
            print(f"[Worker {self.worker_id}] Waiting for senders to complete...")
            print(f"[Worker {self.worker_id}] Logs are being saved to: {log_dir}")
            result = subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file),
                 "wait", "sender_alpha", "sender_bravo"],
                timeout=600,  # 10 minute timeout
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            if result.returncode != 0:
                print(f"[Worker {self.worker_id}] Wait failed:")
                print(result.stderr)
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            
            print(f"[Worker {self.worker_id}] Senders completed, shutting down...")
            
            # Stop log capture
            for proc in log_processes:
                proc.terminate()
                try:
                    proc.wait(timeout=2)
                except subprocess.TimeoutExpired:
                    proc.kill()
            
        finally:
            # Always shutdown stack (even if there was an error)
            subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file), "down", "-v"],
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            
            # Remove camera containers explicitly (they have fixed names and don't get removed by compose down)
            camera_containers = [
                f"mc_camera_alpha_{episode_id}",
                f"mc_camera_bravo_{episode_id}",
                f"mc_camera_alpha_follow_{episode_id}",
                f"mc_camera_bravo_follow_{episode_id}"
            ]
            for container in camera_containers:
                subprocess.run(
                    ["docker", "rm", "-f", container],
                    capture_output=True,
                    text=True
                )
        
        # Run post-processing if needed (similar to run_stack.sh lines 106-134)
        # For now, skip post-processing - can be added later
        print(f"[Worker {self.worker_id}] Episode complete!")
        print(f"[Worker {self.worker_id}] Logs saved to: {log_dir}")

