"""
Base task generator class for Minecraft data collection.

Each task generator corresponds to one task type (chase, orbit, etc.)
and is responsible for:
1. Sampling randomized task configurations
2. Generating docker-compose files with unique ports/displays per worker
3. Running episodes and collecting output
"""

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, Any, Optional
import random
import subprocess
import yaml
import json
import copy
from datetime import datetime
import tempfile

from .base_compose_template import get_base_compose_template


class TaskConfig:
    """Configuration for a single task episode"""
    
    def __init__(self):
        # Bot behavior (randomized per episode)
        self.bot_rng_seed: Optional[int] = None
        self.iterations_per_episode: Optional[int] = None
        self.min_run_actions: Optional[int] = None
        self.max_run_actions: Optional[int] = None
        self.bootstrap_wait_time: Optional[int] = None
        
        # Infrastructure (unique per worker/episode)
        self.mc_port: Optional[int] = None
        self.rcon_port: Optional[int] = None
        self.vnc_display_alpha: Optional[int] = None
        self.vnc_display_bravo: Optional[int] = None
        self.vnc_port_alpha: Optional[int] = None
        self.vnc_port_bravo: Optional[int] = None
        self.novnc_port_alpha: Optional[int] = None
        self.novnc_port_bravo: Optional[int] = None
        self.instance_id: Optional[int] = None
        
        # Paths
        self.data_dir: Optional[str] = None
        self.output_dir: Optional[str] = None
        self.camera_data_dir_alpha: Optional[str] = None
        self.camera_data_dir_bravo: Optional[str] = None
        self.camera_output_dir_alpha: Optional[str] = None
        self.camera_output_dir_bravo: Optional[str] = None
        
        # World configuration (placeholder for future randomization)
        self.world_seed: Optional[int] = None
        self.world_config: Optional[Dict[str, Any]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        return {k: v for k, v in self.__dict__.items() if v is not None}


class BaseTaskGenerator(ABC):
    """
    Base class for task generators.
    Each subclass corresponds to one task type (e.g., chase, orbit).
    """
    
    def __init__(
        self,
        task_name: str,
        output_root: Path,
        data_root: Path,
        camera_root: Path,
        base_port: int = 25565,
        base_rcon_port: int = 25575,
        base_vnc_display: int = 99,
        base_vnc_port: int = 5901,
        base_novnc_port: int = 6901,
        worker_id: int = 0,
        seed: Optional[int] = None
    ):
        """
        Initialize task generator.
        
        Args:
            task_name: Name of the task type (e.g., "chase", "orbit")
            output_root: Root directory for output files
            data_root: Root directory for MC server data
            camera_root: Root directory for camera data/output
            base_port: Base Minecraft server port
            base_rcon_port: Base RCON port
            base_vnc_display: Base X display number for VNC
            base_vnc_port: Base VNC port
            base_novnc_port: Base noVNC port
            worker_id: Unique worker ID (for port/display assignment)
            seed: Random seed for reproducibility
        """
        self.task_name = task_name
        self.output_root = Path(output_root).absolute()
        self.data_root = Path(data_root).absolute()
        self.camera_root = Path(camera_root).absolute()
        
        self.base_port = base_port
        self.base_rcon_port = base_rcon_port
        self.base_vnc_display = base_vnc_display
        self.base_vnc_port = base_vnc_port
        self.base_novnc_port = base_novnc_port
        self.worker_id = worker_id
        
        # Create worker-specific RNG for reproducibility
        self.rng = random.Random(seed if seed is not None else random.randint(0, 2**32-1))
        
        # Counter for episodes generated by this worker
        self.episode_counter = 0
        
        # Create output directories
        self.output_root.mkdir(parents=True, exist_ok=True)
        self.data_root.mkdir(parents=True, exist_ok=True)
        self.camera_root.mkdir(parents=True, exist_ok=True)
    
    @abstractmethod
    def sample_task_config(self) -> TaskConfig:
        """
        Sample randomized parameters for this specific task.
        Each task type implements its own randomization strategy.
        
        Returns:
            TaskConfig with randomized bot behavior parameters
        """
        pass
    
    def run_task_episode(self, save_config: bool = True) -> Dict[str, Any]:
        """
        Generate and run a single episode for this task.
        This is the main entry point similar to run_stack.sh.
        
        Args:
            save_config: Whether to save config JSON for reproducibility
            
        Returns:
            Dictionary with episode metadata and results
        """
        # 1. Sample configuration
        config = self.sample_task_config()
        
        # 2. Setup unique infrastructure settings based on worker_id
        port_offset = self.worker_id * 100
        config.mc_port = self.base_port + port_offset
        config.rcon_port = self.base_rcon_port + port_offset
        config.vnc_display_alpha = self.base_vnc_display + (self.worker_id * 2)
        config.vnc_display_bravo = self.base_vnc_display + (self.worker_id * 2) + 1
        config.vnc_port_alpha = self.base_vnc_port + (self.worker_id * 2)
        config.vnc_port_bravo = self.base_vnc_port + (self.worker_id * 2) + 1
        config.novnc_port_alpha = self.base_novnc_port + (self.worker_id * 2)
        config.novnc_port_bravo = self.base_novnc_port + (self.worker_id * 2) + 1
        config.instance_id = self.worker_id * 10000 + self.episode_counter
        
        # 3. Setup worker-specific directories
        episode_id = f"worker{self.worker_id:03d}_ep{self.episode_counter:06d}"
        
        worker_data_dir = self.data_root / f"worker_{self.worker_id}"
        episode_data_dir = worker_data_dir / f"episode_{self.episode_counter}"
        config.data_dir = str(episode_data_dir)
        config.output_dir = str(self.output_root)
        
        worker_camera_dir = self.camera_root / f"worker_{self.worker_id}" / f"ep_{self.episode_counter}"
        config.camera_data_dir_alpha = str(worker_camera_dir / "data_alpha")
        config.camera_data_dir_bravo = str(worker_camera_dir / "data_bravo")
        config.camera_output_dir_alpha = str(worker_camera_dir / "output_alpha")
        config.camera_output_dir_bravo = str(worker_camera_dir / "output_bravo")
        
        # Create all directories
        for dir_path in [
            config.data_dir,
            config.camera_data_dir_alpha,
            config.camera_data_dir_bravo,
            config.camera_output_dir_alpha,
            config.camera_output_dir_bravo
        ]:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
        
        # 4. Generate docker-compose file
        compose_file = self._generate_compose_file(config, episode_id)
        
        # 5. Save config for reproducibility
        if save_config:
            config_file = self.output_root / f"{episode_id}_{self.task_name}_config.json"
            with open(config_file, 'w') as f:
                json.dump(config.to_dict(), f, indent=2)
        
        # 6. Run the stack (similar to run_stack.sh)
        print(f"[Worker {self.worker_id}] Task: {self.task_name}, Episode: {self.episode_counter}")
        print(f"  MC Port: {config.mc_port}, RCON Port: {config.rcon_port}")
        print(f"  VNC Displays: :{config.vnc_display_alpha}, :{config.vnc_display_bravo}")
        
        start_time = datetime.now()
        try:
            self._run_docker_stack(compose_file, episode_id, config)
            success = True
            error = None
        except Exception as e:
            success = False
            error = str(e)
            print(f"[Worker {self.worker_id}] Episode {self.episode_counter} failed: {e}")
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # 7. Collect output information
        result = {
            "worker_id": self.worker_id,
            "task_name": self.task_name,
            "episode_number": self.episode_counter,
            "episode_id": episode_id,
            "config": config.to_dict(),
            "success": success,
            "error": error,
            "duration_seconds": duration,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
        }
        
        self.episode_counter += 1
        return result
    
    def _generate_compose_file(self, config: TaskConfig, episode_id: str) -> Path:
        """
        Generate docker-compose file by overriding base template.
        
        Args:
            config: TaskConfig with all settings
            episode_id: Unique episode identifier
            
        Returns:
            Path to generated docker-compose file
        """
        compose = copy.deepcopy(get_base_compose_template())
        
        # Get default terrain (flat grass for now, can be overridden by subclasses)
        terrain_json = json.dumps({
            "layers": [
                {"block": "minecraft:bedrock", "height": 1},
                {"block": "minecraft:stone", "height": 124},
                {"block": "minecraft:dirt", "height": 2},
                {"block": "minecraft:grass_block", "height": 1}
            ],
            "biome": "minecraft:plains"
        })
        
        # Override MC server settings
        mc_service = compose["services"]["mc"]
        mc_service["environment"]["SERVER_PORT"] = config.mc_port
        mc_service["environment"]["RCON_PORT"] = config.rcon_port
        mc_service["environment"]["SEED"] = str(config.world_seed) if config.world_seed else ""
        mc_service["environment"]["GENERATOR_SETTINGS"] = terrain_json
        mc_service["volumes"] = [f"{config.data_dir}:/data"]
        mc_service["healthcheck"]["test"] = [
            "CMD-SHELL",
            f"mc-monitor status --host localhost --port {config.mc_port}"
        ]
        
        # Override sender settings (CRITICAL: Set EPISODE_CATEGORY)
        for bot_name in ["sender_alpha", "sender_bravo"]:
            bot_service = compose["services"][bot_name]
            bot_service["environment"]["EPISODE_CATEGORY"] = self.task_name
            bot_service["environment"]["BOT_RNG_SEED"] = str(config.bot_rng_seed)
            bot_service["environment"]["MC_PORT"] = config.mc_port
            bot_service["environment"]["RCON_PORT"] = config.rcon_port
            bot_service["environment"]["BOOTSTRAP_WAIT_TIME"] = config.bootstrap_wait_time
            bot_service["environment"]["MIN_RUN_ACTIONS"] = config.min_run_actions
            bot_service["environment"]["MAX_RUN_ACTIONS"] = config.max_run_actions
            bot_service["environment"]["ITERATIONS_NUM_PER_EPISODE"] = config.iterations_per_episode
            bot_service["volumes"] = [f"{config.output_dir}:/output"]
        
        # Override receiver settings
        for bot_name in ["receiver_alpha", "receiver_bravo"]:
            receiver_service = compose["services"][bot_name]
            receiver_service["environment"]["INSTANCE_ID"] = config.instance_id
            receiver_service["volumes"] = [f"{config.output_dir}:/output"]
        
        # Get absolute paths for camera scripts
        camera_scripts_dir = Path("/home/oscar/mc-multiplayer-data/camera").absolute()
        
        # Override camera_alpha settings
        camera_alpha = compose["services"]["camera_alpha"]
        camera_alpha["container_name"] = f"mc_camera_alpha_{episode_id}"
        camera_alpha["environment"]["MC_PORT"] = str(config.mc_port)
        camera_alpha["environment"]["DISPLAY"] = f":{config.vnc_display_alpha}"
        camera_alpha["environment"]["VNC_PORT"] = str(config.vnc_port_alpha)
        camera_alpha["environment"]["NOVNC_PORT"] = str(config.novnc_port_alpha)
        camera_alpha["volumes"] = [
            f"{config.camera_data_dir_alpha}:/root",
            f"{config.camera_output_dir_alpha}:/output",
            f"{camera_scripts_dir}/entrypoint.sh:/app/entrypoint.sh:ro",
            f"{camera_scripts_dir}/launch_minecraft.py:/app/launch_minecraft.py:ro"
        ]
        
        # Override camera_bravo settings
        camera_bravo = compose["services"]["camera_bravo"]
        camera_bravo["container_name"] = f"mc_camera_bravo_{episode_id}"
        camera_bravo["environment"]["MC_PORT"] = str(config.mc_port)
        camera_bravo["environment"]["DISPLAY"] = f":{config.vnc_display_bravo}"
        camera_bravo["environment"]["VNC_PORT"] = str(config.vnc_port_bravo)
        camera_bravo["environment"]["NOVNC_PORT"] = str(config.novnc_port_bravo)
        camera_bravo["volumes"] = [
            f"{config.camera_data_dir_bravo}:/root",
            f"{config.camera_output_dir_bravo}:/output",
            f"{camera_scripts_dir}/entrypoint.sh:/app/entrypoint.sh:ro",
            f"{camera_scripts_dir}/launch_minecraft.py:/app/launch_minecraft.py:ro"
        ]
        
        # Override camera follow helpers
        camera_alpha_follow = compose["services"]["camera_alpha_follow"]
        camera_alpha_follow["container_name"] = f"mc_camera_alpha_follow_{episode_id}"
        camera_alpha_follow["environment"]["RCON_PORT"] = str(config.rcon_port)
        camera_alpha_follow["volumes"] = [
            f"{camera_scripts_dir}/spectator.js:/app/spectator.js:ro",
            f"{camera_scripts_dir}/package.json:/app/package.json:ro"
        ]
        
        camera_bravo_follow = compose["services"]["camera_bravo_follow"]
        camera_bravo_follow["container_name"] = f"mc_camera_bravo_follow_{episode_id}"
        camera_bravo_follow["environment"]["RCON_PORT"] = str(config.rcon_port)
        camera_bravo_follow["volumes"] = [
            f"{camera_scripts_dir}/spectator.js:/app/spectator.js:ro",
            f"{camera_scripts_dir}/package.json:/app/package.json:ro"
        ]
        
        # Write to temp file
        temp_dir = Path(tempfile.gettempdir()) / f"mc_worker_{self.worker_id}"
        temp_dir.mkdir(exist_ok=True)
        compose_file = temp_dir / f"docker-compose-{episode_id}.yml"
        
        with open(compose_file, 'w') as f:
            yaml.dump(compose, f, default_flow_style=False, sort_keys=False)
        
        return compose_file
    
    def _run_docker_stack(self, compose_file: Path, episode_id: str, config: TaskConfig):
        """
        Run docker compose stack (mimics run_stack.sh).
        
        Args:
            compose_file: Path to docker-compose file
            episode_id: Unique episode identifier
            config: TaskConfig for this episode
        """
        project_name = f"mc_{episode_id}"
        log_dir = self.output_root / "logs" / episode_id
        log_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # Pull images
            print(f"[Worker {self.worker_id}] Pulling images...")
            result = subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file), "pull"],
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            if result.returncode != 0:
                print(f"[Worker {self.worker_id}] Pull failed:")
                print(result.stderr)
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            
            # Start stack
            print(f"[Worker {self.worker_id}] Starting stack...")
            result = subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file), "up", "-d"],
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            if result.returncode != 0:
                print(f"[Worker {self.worker_id}] Start failed:")
                print(result.stderr)
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            
            # Start capturing logs for all services
            log_services = ["mc", "sender_alpha", "sender_bravo", "receiver_alpha", "receiver_bravo",
                          "camera_alpha", "camera_bravo", "camera_alpha_follow", "camera_bravo_follow"]
            log_processes = []
            
            for service in log_services:
                log_file = log_dir / f"{service}.log"
                print(f"[Worker {self.worker_id}] Capturing logs for {service} -> {log_file}")
                with open(log_file, 'w') as f:
                    proc = subprocess.Popen(
                        ["docker", "compose", "-p", project_name, "-f", str(compose_file), 
                         "logs", "--no-color", "--timestamps", "--follow", service],
                        stdout=f,
                        stderr=subprocess.STDOUT,
                        cwd="/home/oscar/mc-multiplayer-data"
                    )
                    log_processes.append(proc)
            
            # Wait for senders to complete
            print(f"[Worker {self.worker_id}] Waiting for senders to complete...")
            print(f"[Worker {self.worker_id}] Logs are being saved to: {log_dir}")
            result = subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file),
                 "wait", "sender_alpha", "sender_bravo"],
                timeout=600,  # 10 minute timeout
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            if result.returncode != 0:
                print(f"[Worker {self.worker_id}] Wait failed:")
                print(result.stderr)
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            
            print(f"[Worker {self.worker_id}] Senders completed, shutting down...")
            
            # Stop log capture
            for proc in log_processes:
                proc.terminate()
                try:
                    proc.wait(timeout=2)
                except subprocess.TimeoutExpired:
                    proc.kill()
            
        finally:
            # Always shutdown stack (even if there was an error)
            subprocess.run(
                ["docker", "compose", "-p", project_name, "-f", str(compose_file), "down", "-v"],
                capture_output=True,
                text=True,
                cwd="/home/oscar/mc-multiplayer-data"
            )
            
            # Remove camera containers explicitly (they have fixed names and don't get removed by compose down)
            camera_containers = [
                f"mc_camera_alpha_{episode_id}",
                f"mc_camera_bravo_{episode_id}",
                f"mc_camera_alpha_follow_{episode_id}",
                f"mc_camera_bravo_follow_{episode_id}"
            ]
            for container in camera_containers:
                subprocess.run(
                    ["docker", "rm", "-f", container],
                    capture_output=True,
                    text=True
                )
        
        # Run post-processing if needed (similar to run_stack.sh lines 106-134)
        # For now, skip post-processing - can be added later
        print(f"[Worker {self.worker_id}] Episode complete!")
        print(f"[Worker {self.worker_id}] Logs saved to: {log_dir}")

